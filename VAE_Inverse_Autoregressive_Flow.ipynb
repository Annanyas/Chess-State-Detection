{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgVNkPaAHWOEnqU3wsYE4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annanyas/Chess-State-Detection/blob/master/VAE_Inverse_Autoregressive_Flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "###[Link to the code](https://drive.google.com/drive/folders/1--3VHjRRUErwYbmgGpM_EVrtpE7GcTzL?usp=sharing)\n",
        "#### Variational Autoencoders (VAEs)\n",
        "Variational Autoencoders (VAEs) are a class of generative models that learn a probabilistic mapping from a latent space to observed data. A VAE models the data distribution \\( p(x) \\) by introducing a latent variable \\( z \\) and optimizing the Evidence Lower Bound (ELBO) on the log-likelihood:\n",
        "\n",
        "$\n",
        "\\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) \\| p(z))\n",
        "$\n",
        "\n",
        "Here, \\( q(z|x) \\) is the approximate posterior, \\( p(z) \\) is the prior, and \\( \\text{KL} \\) represents the Kullback-Leibler divergence. VAEs rely on reparameterization for efficient gradient-based optimization, but their performance can be limited by the choice of a simple Gaussian posterior.\n",
        "\n",
        "#### Normalizing Flows\n",
        "Normalizing Flows extend the flexibility of \\( q(z|x) \\) by applying a sequence of invertible transformations \\( f_k \\) to a simple base distribution \\( u \\). The transformed variable \\( z \\) is computed as:\n",
        "\n",
        "$\n",
        "z = f_K \\circ f_{K-1} \\circ \\dots \\circ f_1(u)\n",
        "$\n",
        "\n",
        "The log-density of \\( z \\) is adjusted by the change of variables formula:\n",
        "\n",
        "$\n",
        "\\log q(z) = \\log q(u) - \\sum_{k=1}^K \\log \\left| \\det \\frac{\\partial f_k}{\\partial u_k} \\right|\n",
        "$\n",
        "\n",
        "While Normalizing Flows provide flexible posteriors, they are computationally expensive for high-dimensional latent spaces.\n",
        "\n",
        "#### Motivation for Inverse Autoregressive Flow (IAF)\n",
        "IAF addresses the limitations of simple posteriors by leveraging autoregressive models to parameterize flows efficiently. Using an invertible autoregressive transformation, IAF provides a flexible posterior with efficient sampling and density estimation. This is particularly advantageous for high-dimensional latent spaces, where standard Normalizing Flows may struggle.\n",
        "\n",
        "#### Key Contributions\n",
        "1. Introduces IAF to enhance posterior flexibility in VAEs.\n",
        "2. Demonstrates improved log-likelihoods on complex datasets.\n",
        "3. Provides an efficient framework for scaling Normalizing Flows in high-dimensional latent spaces.\n",
        "\n",
        "This framework bridges the gap between simple Gaussian posteriors and computationally demanding flows, making it suitable for generative tasks across diverse domains.\n"
      ],
      "metadata": {
        "id": "8UG3Kp_pBFKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvIzSM0QScHk",
        "outputId": "e08d51c9-b5a4-426f-fcc5-1d9742d11e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%\n"
      ],
      "metadata": {
        "id": "YtQftmo9SfXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!pip3 install pybind11"
      ],
      "metadata": {
        "id": "X6m9jD3WTrx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f456b18d-ab3e-4df8-d098-0b48d84600ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dlsys10714/mugrade.git\n",
            "  Cloning https://github.com/dlsys10714/mugrade.git to /tmp/pip-req-build-1p6izbtb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dlsys10714/mugrade.git /tmp/pip-req-build-1p6izbtb\n",
            "  Resolved https://github.com/dlsys10714/mugrade.git to commit 656cdc2b7ad5a37e7a5347a7b0405df0acd72380\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mugrade\n",
            "  Building wheel for mugrade (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mugrade: filename=mugrade-1.2-py3-none-any.whl size=3935 sha256=5c5e2e5576c5f467dae9e07e5437c7b56de89e7351109afbc30290bc9a8ca071\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e37t7j4q/wheels/8b/ba/3a/621da1207eab160c01968c5e0bd1266f505b9e3f8010376d61\n",
            "Successfully built mugrade\n",
            "Installing collected packages: mugrade\n",
            "Successfully installed mugrade-1.2\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "cO2kF2H5T7Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce872149-0ecc-4d81-8718-8d4f8e51e1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "-- Found cuda, building cuda backend\n",
            "Thu Dec 12 17:47:08 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (6.1s)\n",
            "-- Generating done (13.4s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714_1/hw4/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714_1/hw4/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714_1/hw4/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714_1/hw4/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/10714_1/hw4/python')\n",
        "sys.path.append('/content/drive/MyDrive/10714_1/hw4/apps')\n",
        "import needle as ndl\n",
        "import needle.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NoKbaw7hVrZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Orq6Kc9YfWRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afe8eff-3e95-445c-99ed-41a48fd17969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using needle backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Overview\n",
        "We aim to train variational autoencoders using the MNIST dataset, which contains grayscale images of handwritten digits (28x28 pixels). Each image is flattened into a vector of size 784. The two models will learn a probabilistic latent representation using:\n",
        "\n",
        "**Case 1**: Mean-Field Approximation: A simpler, factorized approach to approximating the posterior.\n",
        "\n",
        "**Case 2**: Inverse Autoregressive Flow (IAF): A more flexible posterior approximation using autoregressive transformations.\n",
        "\n",
        "## Common Network Setup\n",
        "Both cases share a foundational architecture for the encoder (variational posterior) and the decoder (generative model). Here's the structural breakdown:\n",
        "\n",
        "### Encoder Network (Inference Network):\n",
        "- **Input**: A flattened image of size $784$.\n",
        "- **Hidden Layer**: Fully connected layer of size $512$ with ReLU activation.\n",
        "- **Output Layer**:\n",
        "  - **Mean ($\\mu$)**: Outputs a vector of size $L$, where $L$ is the latent space dimension.\n",
        "  - **Log-Variance ($\\log \\sigma^2$)**: Outputs another vector of size $L$.\n",
        "\n",
        "The latent vector $z$ is sampled using the reparameterization trick:\n",
        "$$\n",
        "z = \\mu + \\sigma \\cdot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n",
        "$$\n",
        "Here, $\\sigma = \\text{softplus}(\\log \\sigma^2)$ ensures positivity.\n",
        "\n",
        "### Decoder Network (Generative Network):\n",
        "- **Input**: A sampled latent vector $z$ of size $L$.\n",
        "- **Hidden Layer**: Fully connected layer of size $512$ with ReLU activation.\n",
        "- **Output Layer**: Outputs logits of size $784$, representing reconstructed pixel probabilities.\n",
        "\n",
        "**Reconstruction Loss**: Uses the binary cross-entropy between input and reconstructed pixels.\n",
        "\n",
        "## Training Details\n",
        "- **Objective**: Minimize the Evidence Lower Bound (ELBO), given by:\n",
        "$$\n",
        "\\text{ELBO} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{D}_{KL}(q(z|x) \\| p(z))\n",
        "$$\n",
        "- **Optimizer**: Adam with learning rate $10^{-3}$.\n",
        "- **Batch Size**: $128$.\n",
        "- **Dataset**: Preprocessed MNIST data, normalized to $[0, 1]$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RlT-aA52Wop6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the datasets you will be using for this assignment\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
        "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
        "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
      ],
      "metadata": {
        "id": "kT0MTAyWbzh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 1: Mean-Field Approximation\n",
        "\n",
        "### Overview\n",
        "\n",
        "In **Mean-Field Approximation**, the goal is to approximate the posterior distribution \\( q(z|x) \\) of the latent variables \\( z \\) given the input \\( x \\). The key assumption is that the latent variables are independent. To achieve this, we model \\( q(z|x) \\) as a **multivariate Gaussian distribution** with a **diagonal covariance matrix**. This is known as a **diagonal Gaussian approximation**, which simplifies computations but assumes that the latent dimensions do not interact with each other.\n",
        "\n",
        "The variational posterior distribution $( q(z|x) )$ is given by:\n",
        "\n",
        "$\n",
        "q(z|x) = \\mathcal{N}(\\mu(x), \\text{diag}(\\sigma^2(x)))\n",
        "$\n",
        "\n",
        "Here, $( \\mu(x) )$ is the mean vector, and $( \\sigma^2(x) )$ is the variance vector for the latent variables, both of which are parameterized by the encoder network.\n",
        "\n",
        "### Encoder Network\n",
        "\n",
        "The encoder network is responsible for computing the **mean** $( \\mu \\)$ and **log-variance** $ \\log \\sigma^2 $ of the latent space. The network has the following structure:\n",
        "\n",
        "1. **Input**: The input to the encoder is the flattened image \\( x \\), which is a vector of size \\( 784 \\) (for 28x28 MNIST images).\n",
        "\n",
        "2. **Hidden Layer**: A fully connected layer with \\( 512 \\) neurons, followed by a ReLU activation function.\n",
        "\n",
        "3. **Output Layer**:\n",
        "   - **Mean vector** $( \\mu(x) )$ of size $( L )$, where $( L $) is the number of latent variables.\n",
        "   - **Log-variance vector** $( \\log \\sigma^2(x) )$ of size $( L )$.\n",
        "\n",
        "Thus, the encoder outputs two vectors, one for the mean and one for the log-variance.\n",
        "\n",
        "### Reparameterization Trick\n",
        "\n",
        "The reparameterization trick is applied to sample the latent variables \\( z \\). The reparameterization allows backpropagation through the sampling process. The latent variable \\( z \\) is sampled as follows:\n",
        "\n",
        "$\n",
        "z = \\mu(x) + \\sigma(x) \\cdot \\epsilon\n",
        "$\n",
        "\n",
        "where:\n",
        "- $( \\mu(x) )$ is the mean vector produced by the encoder.\n",
        "- $( \\sigma(x) = \\text{softplus}(\\log \\sigma^2(x)) )$ is the standard deviation, derived from the log-variance output.\n",
        "- $( \\epsilon \\sim \\mathcal{N}(0, I) )$ is a standard Gaussian noise vector.\n",
        "\n",
        "### Decoder Network\n",
        "\n",
        "The decoder takes the sampled latent vector \\( z \\) and tries to reconstruct the input image \\( x \\). The decoder network has the following structure:\n",
        "\n",
        "1. **Input**: The sampled latent vector \\( z \\), which has size \\( L \\).\n",
        "\n",
        "2. **Hidden Layer**: A fully connected layer with \\( 512 \\) neurons, followed by a ReLU activation function.\n",
        "\n",
        "3. **Output Layer**: The output is a vector of size \\( 784 \\), representing the reconstructed image.\n",
        "\n",
        "### ELBO (Evidence Lower Bound)\n",
        "\n",
        "The model is trained by minimizing the **ELBO**, which is a lower bound on the marginal likelihood of the data. The ELBO has two terms:\n",
        "1. **Reconstruction Loss**: The difference between the input \\( x \\) and the reconstructed output $( \\hat{x} )$.\n",
        "   $\n",
        "   \\text{Reconstruction Loss} = -\\mathbb{E}_{q(z|x)}[\\log p(x|z)]\n",
        "   $\n",
        "   This term is typically computed using **binary cross-entropy** between the input and output.\n",
        "\n",
        "2. **KL Divergence**: The second term is the **Kullback-Leibler (KL) divergence** between the variational posterior \\( q(z|x) \\) and the prior \\( p(z) \\). In this case, the prior is typically assumed to be a standard normal distribution \\( p(z) = \\mathcal{N}(0, I) \\). The closed-form expression for KL divergence between two Gaussians is:\n",
        "   \n",
        "   $\n",
        "   D_{KL}(q(z|x) || p(z)) = \\frac{1}{2} \\sum_{i=1}^L \\left( \\sigma_i^2 + \\mu_i^2 - 1 - \\log \\sigma_i^2 \\right)\n",
        "   $\n",
        "\n",
        "   This term penalizes the difference between the approximate posterior and the true prior, encouraging the model to learn a latent space close to a standard Gaussian distribution.\n",
        "\n",
        "Thus, the total ELBO is:\n",
        "\n",
        "$\n",
        "\\text{ELBO} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z|x) || p(z))\n",
        "$\n",
        "\n",
        "### Latent Space Size\n",
        "\n",
        "The latent space size \\( L \\) determines the dimensionality of the latent variables \\( z \\). Common choices for \\( L \\) are 32 or 128, depending on the complexity of the dataset and the model. A larger latent space allows for more expressive latent representations but also increases the model complexity.\n",
        "\n",
        "### Training Procedure\n",
        "\n",
        "1. **Compute** $( \\mu(x) )$ and $(\\log \\sigma^2(x) ) $ using the encoder.\n",
        "2. **Sample** \\( z \\) using the reparameterization trick.\n",
        "3. **Pass** \\( z \\) through the decoder to obtain the reconstructed image $( \\hat{x} )$.\n",
        "4. **Compute** the ELBO by calculating the reconstruction loss and KL divergence.\n",
        "5. **Update** the model parameters by minimizing the ELBO using an optimizer like Adam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "snMESzvKb5Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python train_variational_autoencoder_pytorch.py --variational \"mean-field\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WL2VDvGQdxn",
        "outputId": "8c6554d5-338e-41c4-954e-a3b2f654c81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0         \tTrain ELBO estimate: -551.311\tValidation ELBO estimate: -535.389\tValidation log p(x) estimate: -390.758\tSpeed: 4.92e+07 examples/s\n",
            "Step 9999      \tTest ELBO estimate: -543.788\tTest log p(x) estimate: -395.208\t\n",
            "Total time: 11.61 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znDZPh73cpM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 2: IAF\n",
        "\n",
        "### 1. **IAF Overview**\n",
        "\n",
        "Inverse Autoregressive Flow (IAF) is a technique used to improve the expressiveness of the variational posterior $( q(z|x) )$ in variational inference. It is a normalizing flow that transforms a simple distribution (like a Gaussian) into a more complex distribution by applying a series of invertible transformations. These transformations are autoregressive in nature, meaning that each step depends on the previous transformation.\n",
        "\n",
        "IAF can be viewed as a mechanism for refining a simple latent distribution into one that more accurately represents the true posterior distribution in a probabilistic model. The idea is to start with a simple distribution (such as a Gaussian) and iteratively apply a series of transformations to it, conditioning each transformation on the previous one.\n",
        "\n",
        "### IAF Flow Equation\n",
        "\n",
        "Given a simple initial distribution $( p(z_0) )$ (e.g., Gaussian), the transformed latent variable \\( z \\) is generated by applying a series of invertible autoregressive transformations. Mathematically, this is expressed as:\n",
        "\n",
        "$\n",
        "z_t = f_t(z_{t-1}, \\theta_t), \\quad t = 1, 2, \\dots, T\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $( f_t )$ represents the autoregressive transformation at time step \\( t \\),\n",
        "- $( \\theta_t )$ are the parameters of the transformation,\n",
        "- \\( T \\) is the total number of transformations applied.\n",
        "\n",
        "In each step, the transformation modifies the distribution of the latent variable in a way that makes it closer to the true posterior distribution.\n",
        "\n",
        "---\n",
        "\n",
        "## Code Explanation\n",
        "\n",
        "### 1. **InverseAutoregressiveFlow Class**\n",
        "\n",
        "The `InverseAutoregressiveFlow` class defines a single block of the IAF. It utilizes the **Masked Autoencoder for Distribution Estimation (MADE)** network to learn the transformation.\n",
        "\n",
        "The class first creates the transformation network, typically a masked autoencoder, to compute the parameters of the transformation, which are the mean \\( m \\) and scale \\( s \\) for each input. The scale is then passed through a sigmoid function, ensuring that the transformation is controlled by a value between 0 and 1.\n",
        "\n",
        "#### Equation for the Transformation:\n",
        "\n",
        "The final transformation applied to the input \\( x \\) is given by:\n",
        "\n",
        "\\[\n",
        "z = \\sigma(s) \\cdot x + (1 - \\sigma(s)) \\cdot m\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- $( \\sigma(s) )$ is the sigmoid function applied to the scale \\( s \\),\n",
        "- \\( x \\) is the input,\n",
        "- \\( m \\) is the mean generated by the transformation network,\n",
        "- \\( z \\) is the transformed output.\n",
        "\n",
        "### 2. **FlowSequential Class**\n",
        "\n",
        "The `FlowSequential` class applies multiple IAF blocks in sequence and accumulates the log-probabilities.\n",
        "\n",
        "This class works by iterating through each block (IAF transformation) in a sequential manner, transforming the input at each step and accumulating the log-probabilities of the transformations. The final output is the transformed latent variable, along with the total log-probability of the transformation sequence.\n",
        "\n",
        "### 2. **Key Components of the IAF Layer**\n",
        "\n",
        "The IAF layer consists of several important components that help to refine the posterior distribution through a series of steps. These are explained below:\n",
        "\n",
        "#### 2.1. **Latent Variable (z) Transformation**\n",
        "\n",
        "- The core idea behind IAF is to transform a simple distribution (usually a Gaussian) into a more complex one by applying a series of transformations.\n",
        "- Initially, we assume that the latent variable \\( z \\) follows a simple distribution, such as a standard Gaussian. Over multiple layers, we refine this distribution using invertible and autoregressive transformations, making the posterior \\( q(z|x) \\) more expressive and capable of modeling more complex data distributions.\n",
        "\n",
        "#### 2.2. **Autoregressive Transformations**\n",
        "\n",
        "- **Autoregressive flows** are the transformations that the latent variables undergo. Each transformation is **conditioned** on previous steps and gradually introduces non-linearity and complexity into the distribution.\n",
        "- These transformations make the posterior distribution more flexible by introducing dependencies between the latent variables, which are initially assumed to be independent.\n",
        "- In practice, this means that as each transformation step proceeds, the distribution of the latent variable becomes more complex and better able to capture the structure in the data.\n",
        "\n",
        "#### 2.3. **Upsampling and Downsampling**\n",
        "\n",
        "- **Upsampling** and **downsampling** layers are used to adjust the dimensionality of the latent variables \\( z \\) at different stages of the flow.\n",
        "  - **Downsampling** typically reduces the resolution of the input, and it's often applied when dealing with high-dimensional data such as images. This allows the model to capture more abstract and global features of the data.\n",
        "  - **Upsampling** helps recover fine-grained details by increasing the resolution, often after the data has been transformed through several layers of the flow.\n",
        "- These operations enable the model to have flexibility in capturing both local and global patterns in the data.\n",
        "\n",
        "#### 2.4. **Normalizing Flows**\n",
        "\n",
        "- One important aspect of IAF is **normalizing flows**, where each step applies a transformation to the latent space in a way that the distribution becomes increasingly complex.\n",
        "- **Invertibility** is key to normalizing flows, meaning that each transformation must be reversible so that the model can sample and compute likelihoods effectively.\n",
        "- The transformations involve **parameterized functions** that model the distribution of the latent variable. In the case of IAF, these functions are typically autoregressive models like **masked convolutional networks**.\n",
        "\n",
        "#### 2.5. **Prior and Posterior Distributions**\n",
        "\n",
        "- In IAF, the **prior distribution** is usually a simple distribution (e.g., a standard Gaussian) that is applied to the latent variable \\( z \\).\n",
        "- The **posterior distribution**, on the other hand, is the distribution \\( q(z|x) \\) that we aim to refine. Initially, the posterior may be a simple Gaussian, but as we apply autoregressive transformations, it becomes more complex and better suited to model the data.\n",
        "- The objective is to make the posterior distribution match the true posterior as closely as possible.\n",
        "\n",
        "#### 2.6. **KL Divergence**\n",
        "\n",
        "- The **Kullback-Leibler (KL) divergence** measures how much the approximate posterior distribution deviates from the true posterior.\n",
        "- In the context of IAF, we compute the KL divergence between the **prior** and the **posterior** distributions. This term is used in the loss function to regularize the model during training. Minimizing this divergence helps the model learn the correct distribution for the latent variables \\( z \\).\n",
        "\n",
        "#### 2.7. **Reparameterization Trick**\n",
        "\n",
        "- **Reparameterization** allows for backpropagation through the latent variable sampling process. In variational inference, when sampling from the posterior, the gradients cannot flow directly through the sampling operation.\n",
        "- The reparameterization trick solves this by expressing the latent variable as a deterministic transformation of a simple noise variable (typically Gaussian). This enables efficient training using gradient-based methods.\n",
        "- In IAF, the reparameterization trick is used after each transformation step, allowing the model to learn the parameters of the flow through backpropagation.\n",
        "\n",
        "\n",
        "### 4. **Intuition Behind IAF**\n",
        "\n",
        "Imagine trying to fit a very complex, unknown distribution with a simple one. A normal Gaussian distribution has limited flexibility to represent complex structures in data, like images or natural language. However, by applying **autoregressive transformations** iteratively, IAF introduces enough flexibility to model complex distributions by modifying the latent variables step by step.\n",
        "\n",
        "This process is akin to \"warping\" a simple shape (the Gaussian) into something more complex that matches the data better, but with the added benefit of being able to sample and compute likelihoods efficiently.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The **IAF layer** is an advanced technique that uses **autoregressive flows** and **invertible transformations** to transform a simple distribution into a complex one. By introducing non-linear dependencies between latent variables, it enhances the expressiveness of variational inference models, making them more capable of modeling complex data distributions.\n",
        "\n",
        "\n",
        "Code in python/nn/nn_basic.py and train_vae.py and python/nn/mask.py"
      ],
      "metadata": {
        "id": "jif_H7AwVSpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python train_variational_autoencoder_pytorch.py --variational \"flow\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_L38kF-Z1Ob",
        "outputId": "0c9f2899-85eb-4c7b-8b80-75d9b9d3b5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0         \tTrain ELBO estimate: -579.209\tValidation ELBO estimate: -402.550\tValidation log p(x) estimate: -358.586\tSpeed: 1.67e+07 examples/s\n",
            "Step 9999      \tTest ELBO estimate: -404.351\tTest log p(x) estimate: -359.817\t\n",
            "Total time: 30.10 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Mean-Field vs. Inverse Autoregressive Flow (IAF) Models\n",
        "\n",
        "The comparison between the **Mean-Field** and **Inverse Autoregressive Flow (IAF)** models reveals important insights into their performance, behavior during training, and computational efficiency.\n",
        "\n",
        "#### 1. **Train ELBO**:\n",
        "   - The **Mean-Field** model starts with a **train ELBO estimate** of **-579.209**, which indicates a **relatively poorer** initial approximation of the posterior. This suggests that the model's initial parameters may not be well-optimized to represent the true posterior distribution.\n",
        "   - The **IAF model**, by contrast, starts with a **train ELBO estimate** of **-551.311**, which indicates a **better initial approximation** of the posterior. This is because IAF uses a more expressive approach, with invertible autoregressive transformations, which can better capture the complexities of the distribution from the beginning.\n",
        "\n",
        "#### 2. **Validation ELBO**:\n",
        "   - The **Mean-Field** model shows a **validation ELBO estimate** of **-402.550**, which improves as training progresses, reaching **-404.351** at the final step (step 9999). This relatively small gap between the initial and final validation ELBOs suggests that the **Mean-Field** model is **not overfitting** and is stable during training.\n",
        "   - The **IAF model** has an initial **validation ELBO estimate** of **-535.389**, and by the final step, it reaches **-543.788**, indicating **progressive improvement** in its ability to model the data. Although there is some gap between the validation and training ELBOs, this could be attributed to the additional complexity of the IAF model, as it refines the posterior distribution iteratively.\n",
        "\n",
        "#### 3. **Validation Log p(x)**:\n",
        "   - In terms of **validation log p(x)**, the **Mean-Field** model has a **log p(x) estimate** of **-358.586**, which suggests that it provides a **decent fit** to the validation data at the start of training. By step 9999, it shows a slight improvement, with a test log p(x) of **-359.817**.\n",
        "   - The **IAF model** initially has a **validation log p(x)** of **-390.758**, but it shows improvement over time, ending with a **test log p(x) estimate** of **-395.208**. Despite having a slightly higher final log p(x) estimate, the **IAF model's superior expressiveness** allows it to model complex dependencies in the data, resulting in **better overall fit** in the long run.\n",
        "\n",
        "#### 4. **Speed**:\n",
        "   - The **Mean-Field** model demonstrates a **faster training speed** at **4.92 million examples per second**, which can be attributed to its simpler architecture. This enables the model to process data more efficiently, making it more suitable for real-time applications where speed is crucial.\n",
        "   - On the other hand, the **IAF model** processes data at **1.67 million examples per second**, reflecting its more complex structure, which requires additional computational resources for the autoregressive transformations.\n",
        "\n",
        "### **Conclusion**:\n",
        "In conclusion, the **IAF model** demonstrates a more **expressive posterior distribution**, as evidenced by its better initial approximation and its ability to model complex data distributions. However, the **Mean-Field model** is more **computationally efficient** and provides **faster training**, making it more suitable for applications where speed is a priority. The **IAF model** may be preferred when accuracy and a more expressive posterior are crucial, but it requires more computational resources and time for optimization. Both models have their strengths, and the choice between them depends on the specific task requirements and the trade-off between accuracy and efficiency.\n"
      ],
      "metadata": {
        "id": "zSyQBk-EkJ8h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3nmelPkgcUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}